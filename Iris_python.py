# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z7X8FBwHRqwMRPY8wc9_rkZiQ_gNhqU3
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import joblib

# Step 1: Load dataset from Google Drive
filepath = "/content/drive/MyDrive/Iris.csv"
data = pd.read_csv(filepath)
data.info()

# Step 2: Display data shape and preview
print("Shape of the dataset:", data.shape)
print("First 20 rows:\n", data.head(20))

# Step 3: Plot and save histograms silently
data.hist()
plt.savefig("histograms.png")
plt.close()

# Step 4: Plot and save density plots silently
data.plot(kind='density', subplots=True, layout=(3,3), sharex=False)
plt.savefig("density_plots.png")
plt.close()

# Step 5: Convert to NumPy array and extract features/labels
array = data.values
X = array[:, 1:5]  # Features: Sepal and Petal measurements
Y = array[:, 5]    # Target: Species

# Step 6: Split data into training (67%) and testing (33%)
test_size = 0.33
seed = 7
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)

# Step 7: Create and train logistic regression model
model = LogisticRegression(max_iter=200)
model.fit(X_train, Y_train)

# Step 8: Evaluate and display accuracy
result = model.score(X_test, Y_test)
print("Accuracy: {:.2f}%".format(result * 100))

# Step 9: Save the trained model to a file
joblib.dump(model, "logistic_model.pkl")